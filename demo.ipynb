{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UchihaIthachi/cuda-gpu-programming-lab/blob/main/cuda-lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsLkPMbf3rQh"
      },
      "source": [
        "# CUDA Lab Setup\n",
        "\n",
        "This notebook will guide you through setting up and running the `cuda-lab` examples in Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRhbEekk3rQk"
      },
      "source": [
        "## 1. Check GPU Availability\n",
        "\n",
        "First, let's ensure that a GPU is available. Go to **Runtime -> Change runtime type** and select **GPU** as the hardware accelerator. Then, run the following cell to verify that Colab has assigned a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "fcss37C03rQl",
        "outputId": "df5281f8-f32f-4dcc-f980-39315d08ff9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug 24 14:35:55 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fdQmMxs3rQm"
      },
      "source": [
        "## 2. Clone the Repository\n",
        "\n",
        "Next, clone the `cuda-lab` repository from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "tdeKzY4U3rQm",
        "outputId": "8ae1e619-1ddb-4809-ab91-1c3e3f890b70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cuda-gpu-programming-lab'...\n",
            "remote: Enumerating objects: 137, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 137 (delta 65), reused 84 (delta 30), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (137/137), 50.11 KiB | 789.00 KiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "/content/cuda-gpu-programming-lab/cuda-gpu-programming-lab/cuda-gpu-programming-lab/cuda-gpu-programming-lab\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/UchihaIthachi/cuda-gpu-programming-lab.git\n",
        "%cd cuda-gpu-programming-lab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq1sFm2s6lqK"
      },
      "source": [
        "## 3. Set GPU_ARCH Environment Variable\n",
        "\n",
        "The `Makefile` is designed to automatically detect the GPU architecture. However, you can explicitly set the `GPU_ARCH` environment variable to override this. This cell determines the GPU's compute capability and sets the `ARCH` variable for the `make` commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "gHwX1sVd6lqL",
        "outputId": "1755002e-562a-42fd-df93-526a0a746131",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected GPU architecture: sm_75\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "from subprocess import check_output\n",
        "\n",
        "def get_gpu_arch():\n",
        "    try:\n",
        "        output = check_output(['nvidia-smi', '--query-gpu=compute_cap', '--format=csv,noheader']).decode('utf-8').strip()\n",
        "        if output:\n",
        "            major, minor = re.search(r'(\\d+)\\.(\\d+)', output).groups()\n",
        "            return f\"sm_{major}{minor}\"\n",
        "    except Exception as e:\n",
        "        print(f\"Could not determine GPU architecture: {e}\")\n",
        "    return \"sm_50\"  # Fallback to a default architecture\n",
        "\n",
        "ARCH = get_gpu_arch()\n",
        "os.environ['ARCH'] = ARCH\n",
        "print(f\"Detected GPU architecture: {ARCH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDIPp57Z3rQn"
      },
      "source": [
        "## 4. Build the CUDA Programs\n",
        "\n",
        "Now, let's compile all the CUDA and serial programs using `make`. The compiled binaries will be placed in the `bin/` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "eoYAks6g3rQn",
        "outputId": "56e1d864-99c9-40ef-99d1-ba307630fbd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir -p ./bin\n",
            "nvcc -O2 -std=c++14 -gencode arch=compute_75,code=sm_75 -I./include -o bin/00_device_query src/00_device_query.cu\n",
            "nvcc -O2 -std=c++14 -gencode arch=compute_75,code=sm_75 -I./include -o bin/01_hello_kernel src/01_hello_kernel.cu\n",
            "nvcc -O2 -std=c++14 -gencode arch=compute_75,code=sm_75 -I./include -o bin/02_vector_add src/02_vector_add.cu\n",
            "nvcc -O2 -std=c++14 -gencode arch=compute_75,code=sm_75 -I./include -o bin/03_saxpy src/03_saxpy.cu\n",
            "nvcc -O2 -std=c++14 -gencode arch=compute_75,code=sm_75 -I./include -o bin/04_matmul_naive src/04_matmul_naive.cu\n",
            "nvcc -O2 -std=c++14 -gencode arch=compute_75,code=sm_75 -I./include -o bin/05_matmul_tiled_shared src/05_matmul_tiled_shared.cu\n",
            "nvcc -O2 -std=c++14 -gencode arch=compute_75,code=sm_75 -I./include -o bin/06_reduction_sum src/06_reduction_sum.cu\n",
            "nvcc -O2 -std=c++14 -gencode arch=compute_75,code=sm_75 -I./include -o bin/07_histogram_atomics src/07_histogram_atomics.cu\n",
            "nvcc -O2 -std=c++14 -gencode arch=compute_75,code=sm_75 -I./include -o bin/08_pi_monte_carlo src/08_pi_monte_carlo.cu\n",
            "g++ -O2 -std=c++14 -Wall -I./include -o bin/serial_histogram src/serial/serial_histogram.cpp\n",
            "g++ -O2 -std=c++14 -Wall -I./include -o bin/serial_matmul src/serial/serial_matmul.cpp\n",
            "g++ -O2 -std=c++14 -Wall -I./include -o bin/serial_pi_monte_carlo src/serial/serial_pi_monte_carlo.cpp\n",
            "g++ -O2 -std=c++14 -Wall -I./include -o bin/serial_reduction_sum src/serial/serial_reduction_sum.cpp\n",
            "g++ -O2 -std=c++14 -Wall -I./include -o bin/serial_saxpy src/serial/serial_saxpy.cpp\n",
            "g++ -O2 -std=c++14 -Wall -I./include -o bin/serial_vector_add src/serial/serial_vector_add.cpp\n",
            "\u001b[01m\u001b[Ksrc/serial/serial_vector_add.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint main(int, char**)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/serial/serial_vector_add.cpp:15:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbytes\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   15 |     size_t \u001b[01;35m\u001b[Kbytes\u001b[m\u001b[K = (size_t)n * sizeof(float);\n",
            "      |            \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n"
          ]
        }
      ],
      "source": [
        "!make all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ieSo-iD3rQn"
      },
      "source": [
        "## 5. Run Examples and Performance Comparison\n",
        "\n",
        "You can now run any of the compiled programs. Here are a few examples, along with a performance comparison between the serial and CUDA versions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1tEGDQe3rQn"
      },
      "source": [
        "### Device Query\n",
        "\n",
        "This program lists the available CUDA devices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "eY0T_K4u3rQo",
        "outputId": "cd1da66a-d42a-41bd-f136-2065c7379bba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 00_device_query...\n",
            "././bin/00_device_query \n",
            "Found 1 CUDA device(s)\n",
            "-- Device 0: Tesla T4 | CC 7.5 | SMs=40 | Mem=15.83 GB\n"
          ]
        }
      ],
      "source": [
        "!make run PROG=00_device_query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d62ouZH1OcVr"
      },
      "source": [
        "### Hello Kernel\n",
        "\n",
        "A simple \"Hello, World!\" from the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "OGDcZ_jWOcVr",
        "outputId": "1e0b2797-9c88-4a62-94d0-7cb47652c29d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 01_hello_kernel...\n",
            "././bin/01_hello_kernel \n",
            "Hello from block 0, thread 0\n",
            "Hello from block 0, thread 1\n",
            "Hello from block 0, thread 2\n",
            "Hello from block 0, thread 3\n",
            "Hello from block 1, thread 0\n",
            "Hello from block 1, thread 1\n",
            "Hello from block 1, thread 2\n",
            "Hello from block 1, thread 3\n",
            "Host: done.\n"
          ]
        }
      ],
      "source": [
        "!make run PROG=01_hello_kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veFDRVTi3rQo"
      },
      "source": [
        "### Vector Addition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6wbDUcxOcVs"
      },
      "source": [
        "This example adds two vectors. We will compare the performance of the serial and CUDA implementations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "7nRn82ZG3rQo",
        "outputId": "8cd3b9e5-7732-4359-ebdd-a2f71fe04e5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Serial: serial_vector_add ---\n",
            "Running serial_vector_add...\n",
            "././bin/serial_vector_add -n 10000000\n",
            "serial_vector_add: n=10000000 -> 11.672 ms\n",
            "\n",
            "--- Running CUDA: 02_vector_add ---\n",
            "Running 02_vector_add...\n",
            "././bin/02_vector_add -n 10000000\n",
            "vec_add: n=10000000 t=256 -> 0.503 ms, OK=true, BW=238.35 GB/s\n",
            "\n",
            "--- Performance Comparison ---\n",
            "Serial execution time: 11.672 ms\n",
            "CUDA execution time:   0.503 ms\n",
            "Speedup: 23.20x\n"
          ]
        }
      ],
      "source": [
        "!python scripts/compare.py \\\n",
        "    serial_vector_add \\\n",
        "    02_vector_add \\\n",
        "    \"serial_vector_add: n=\\d+ -> (\\d+\\.\\d+) ms\" \\\n",
        "    \"vec_add: n=\\d+ t=\\d+ -> (\\d+\\.\\d+) ms\" \\\n",
        "    --args \"-n 10000000\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tfcv4h-23rQo"
      },
      "source": [
        "### SAXPY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "daJXgJa13rQo",
        "outputId": "a5abf715-1855-4eb8-876e-4e877ded6d3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Serial: serial_saxpy ---\n",
            "Running serial_saxpy...\n",
            "././bin/serial_saxpy -n 10000000\n",
            "serial_saxpy: n=10000000 a=2.50 -> 11.179 ms, OK=true\n",
            "\n",
            "--- Running CUDA: 03_saxpy ---\n",
            "Error running command: make run PROG=03_saxpy ARGS=\"-n 10000000\"\n",
            "make: *** [Makefile:77: run] Error 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python scripts/compare.py \\\n",
        "    serial_saxpy \\\n",
        "    03_saxpy \\\n",
        "    \"serial_saxpy: n=\\d+ -> (\\d+\\.\\d+) ms\" \\\n",
        "    \"saxpy: n=\\d+ t=\\d+ -> (\\d+\\.\\d+) ms\" \\\n",
        "    --args \"-n 10000000\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeWJgP54OcVs"
      },
      "source": [
        "### Matrix Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "fywOwXohOcVs",
        "outputId": "3ba8db4b-7195-4d97-b39d-0b9d127bc333",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running command: make run PROG=serial_matmul ARGS='-m 1024 -n 1024 -k 1024'\n",
            "Running serial_matmul...\n",
            "././bin/serial_matmul -m 1024 -n 1024 -k 1024\n",
            "serial_matmul: 1024x1024x1024 -> 3241.066 ms, 0.66 GF/s\n",
            "\n",
            "Running command: make run PROG=04_matmul_naive ARGS='-m 1024 -n 1024 -k 1024'\n",
            "Running 04_matmul_naive...\n",
            "././bin/04_matmul_naive -m 1024 -n 1024 -k 1024\n",
            "mm_naive: 1024x1024x1024 TB=16 -> 9.238 ms, 232.47 GF/s, maxdiff=9.54e-07\n",
            "\n",
            "Running command: make run PROG=05_matmul_tiled_shared ARGS='-m 1024 -n 1024 -k 1024'\n",
            "Running 05_matmul_tiled_shared...\n",
            "././bin/05_matmul_tiled_shared -m 1024 -n 1024 -k 1024\n",
            "mm_tiled: 1024x1024x1024 TILE=16 -> 5.844 ms, 367.48 GF/s, maxdiff=9.54e-07\n",
            "\n",
            "--- Performance Comparison ---\n",
            "Serial execution time:       3241.066 ms\n",
            "CUDA Naive execution time:   9.238 ms (Speedup: 350.84x)\n",
            "CUDA Tiled execution time:   5.844 ms (Speedup: 554.60x)\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import subprocess\n",
        "\n",
        "def run_and_parse_time(command, pattern):\n",
        "    print(f\"Running command: {command}\")\n",
        "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
        "    if result.returncode != 0:\n",
        "        print(f\"Error running command: {command}\\n{result.stderr}\")\n",
        "        return None, None\n",
        "    output = result.stdout\n",
        "    print(output)\n",
        "    match = re.search(pattern, output)\n",
        "    time = float(match.group(1)) if match else None\n",
        "    return output, time\n",
        "\n",
        "m, n, k = 1024, 1024, 1024\n",
        "args = f\"-m {m} -n {n} -k {k}\"\n",
        "\n",
        "# Run Serial\n",
        "_, serial_time = run_and_parse_time(\n",
        "    f\"make run PROG=serial_matmul ARGS='{args}'\",\n",
        "    r\"serial_matmul: .*? -> (\\d+\\.\\d+) ms\"\n",
        ")\n",
        "\n",
        "# Run Naive CUDA\n",
        "_, cuda_naive_time = run_and_parse_time(\n",
        "    f\"make run PROG=04_matmul_naive ARGS='{args}'\",\n",
        "    r\"mm_naive: .*? -> (\\d+\\.\\d+) ms\"\n",
        ")\n",
        "\n",
        "# Run Tiled CUDA\n",
        "_, cuda_tiled_time = run_and_parse_time(\n",
        "    f\"make run PROG=05_matmul_tiled_shared ARGS='{args}'\",\n",
        "    r\"mm_tiled: .*? -> (\\d+\\.\\d+) ms\"\n",
        ")\n",
        "\n",
        "# Comparison\n",
        "print(\"--- Performance Comparison ---\")\n",
        "if all([serial_time, cuda_naive_time, cuda_tiled_time]):\n",
        "    speedup_naive = serial_time / cuda_naive_time if cuda_naive_time > 0 else float('inf')\n",
        "    speedup_tiled = serial_time / cuda_tiled_time if cuda_tiled_time > 0 else float('inf')\n",
        "    print(f\"Serial execution time:       {serial_time:.3f} ms\")\n",
        "    print(f\"CUDA Naive execution time:   {cuda_naive_time:.3f} ms (Speedup: {speedup_naive:.2f}x)\")\n",
        "    print(f\"CUDA Tiled execution time:   {cuda_tiled_time:.3f} ms (Speedup: {speedup_tiled:.2f}x)\")\n",
        "else:\n",
        "    print(\"Could not parse execution time from one or more runs.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGmZZxnMOcVt"
      },
      "source": [
        "### Reduction Sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "nmg_4aYZOcVt",
        "outputId": "eb9b484d-8e64-4276-fe05-69e2c572a1ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Serial: serial_reduction_sum ---\n",
            "Running serial_reduction_sum...\n",
            "././bin/serial_reduction_sum -n 10000000\n",
            "serial_reduction_sum: n=10000000 -> 12.903 ms, sum=7.5e+06\n",
            "\n",
            "--- Running CUDA: 06_reduction_sum ---\n",
            "Running 06_reduction_sum...\n",
            "././bin/06_reduction_sum -n 10000000\n",
            "reduction_sum: n=10000000 t=256 -> 0.606 ms\n",
            "\n",
            "--- Performance Comparison ---\n",
            "Serial execution time: 12.903 ms\n",
            "CUDA execution time:   0.606 ms\n",
            "Speedup: 21.29x\n"
          ]
        }
      ],
      "source": [
        "!python scripts/compare.py \\\n",
        "    serial_reduction_sum \\\n",
        "    06_reduction_sum \\\n",
        "    \"serial_reduction_sum: n=\\d+ -> (\\d+\\.\\d+) ms\" \\\n",
        "    \"reduction_sum: n=\\d+ t=\\d+ -> (\\d+\\.\\d+) ms\" \\\n",
        "    --args \"-n 10000000\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAx6IEvXOcVt"
      },
      "source": [
        "### Histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vo9kQ55POcVt",
        "outputId": "878b47f2-b090-4561-f9e9-409475d03b7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Serial: serial_histogram ---\n",
            "Running serial_histogram...\n",
            "././bin/serial_histogram -n 10000000\n",
            "serial_histogram: n=10000000 -> 42.349 ms\n",
            "\n",
            "--- Running CUDA: 07_histogram_atomics ---\n",
            "Running 07_histogram_atomics...\n",
            "././bin/07_histogram_atomics -n 10000000\n",
            "histogram: n=10000000 t=256 -> 5.980 ms\n",
            "\n",
            "--- Performance Comparison ---\n",
            "Serial execution time: 42.349 ms\n",
            "CUDA execution time:   5.980 ms\n",
            "Speedup: 7.08x\n"
          ]
        }
      ],
      "source": [
        "!python scripts/compare.py \\\n",
        "    serial_histogram \\\n",
        "    07_histogram_atomics \\\n",
        "    \"serial_histogram: n=\\d+ -> (\\d+\\.\\d+) ms\" \\\n",
        "    \"histogram: n=\\d+ t=\\d+ -> (\\d+\\.\\d+) ms\" \\\n",
        "    --args \"-n 10000000\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mionhk6FOcVt"
      },
      "source": [
        "### Pi Monte Carlo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ZhnbU-WIOcVt",
        "outputId": "0ae970d5-2ea8-47f5-c7b7-28ee0f26ad9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Serial: serial_pi_monte_carlo ---\n",
            "Running serial_pi_monte_carlo...\n",
            "././bin/serial_pi_monte_carlo -n 100000000\n",
            "serial_pi_monte_carlo: n=100000000 pi=3.14156264 -> 283.823 ms\n",
            "\n",
            "--- Running CUDA: 08_pi_monte_carlo ---\n",
            "Running 08_pi_monte_carlo...\n",
            "././bin/08_pi_monte_carlo -n 100000000\n",
            "pi_monte_carlo: n=100000000 t=256 pi=3.14158480 -> 0.768 ms\n",
            "\n",
            "--- Performance Comparison ---\n",
            "Serial execution time: 283.823 ms\n",
            "CUDA execution time:   0.768 ms\n",
            "Speedup: 369.56x\n"
          ]
        }
      ],
      "source": [
        "!python scripts/compare.py \\\n",
        "    serial_pi_monte_carlo \\\n",
        "    08_pi_monte_carlo \\\n",
        "    \"serial_pi_monte_carlo: n=\\d+ pi=.+ -> (\\d+\\.\\d+) ms\" \\\n",
        "    \"pi_monte_carlo: n=\\d+ t=\\d+ pi=.+ -> (\\d+\\.\\d+) ms\" \\\n",
        "    --args \"-n 100000000\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76HJSQm63rQo"
      },
      "source": [
        "## 5. Run Tests\n",
        "\n",
        "To ensure everything is working correctly, you can run the provided tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7jLRaI63rQo",
        "outputId": "2d6045d1-0197-4fac-e2d3-0ac2ac66c9fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -O2 -std=c++14 -gencode arch=compute_75,code=sm_75 -I./include -o bin/test_test_matmul tests/test_matmul.cu\n",
            "nvcc -O2 -std=c++14 -gencode arch=compute_75,code=sm_75 -I./include -o bin/test_test_reduce tests/test_reduce.cu\n",
            "nvcc -O2 -std=c++14 -gencode arch=compute_75,code=sm_75 -I./include -o bin/test_test_vec tests/test_vec.cu\n",
            "Running tests...\n",
            "use 04/05 matmul\n",
            "use 06_reduction_sum\n",
            "use 02_vector_add\n"
          ]
        }
      ],
      "source": [
        "!make test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-65L_Ar3rQp"
      },
      "source": [
        "## 6. Clean Up\n",
        "\n",
        "You can remove the compiled binaries and other build artifacts by running `make clean`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1uU0ovc3rQp"
      },
      "outputs": [],
      "source": [
        "!make clean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlG8mk5TOcVu"
      },
      "source": [
        "## 7. Run All Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcbnY88gOcVu"
      },
      "outputs": [],
      "source": [
        "!make test"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}