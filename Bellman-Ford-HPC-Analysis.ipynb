{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis of Bellman-Ford HPC Implementations (Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a complete workflow to set up the environment, run benchmarks, and analyze the performance of four different implementations of the Bellman-Ford algorithm on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's set up the environment. This involves checking for a GPU, cloning the project repository from GitHub, and installing Python dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Check GPU Availability\n",
    "\n",
    "Ensure that a GPU is available. Go to **Runtime -> Change runtime type** and select **GPU** as the hardware accelerator. The following cell should show your assigned GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Clone the Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/UchihaIthachi/bellman-ford-hpc-openmp-cuda.git\n",
    "%cd bellman-ford-hpc-openmp-cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the Executables\n",
    "\n",
    "Next, we compile the C/C++ and CUDA source code. The `Makefile` will automatically detect the GPU architecture and build the executables in the `bin/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make clean && make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the Benchmarks\n",
    "\n",
    "Now, we'll run our custom benchmarking script, `scripts/benchmark.py`. This script will execute each Bellman-Ford implementation across a range of graph sizes and save the timing results to `benchmark_results.json`.\n",
    "\n",
    "You can customize the vertex counts by modifying the `--vertices` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./scripts/benchmark.py --vertices 1000 2000 5000 10000 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze the Results\n",
    "\n",
    "With the benchmarks complete, let's load the results into a pandas DataFrame and examine the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "try:\n",
    "    with open('benchmark_results.json', 'r') as f:\n",
    "        results = json.load(f)\n",
    "    df = pd.DataFrame(results)\n",
    "    print(\"Benchmark Results:\")\n",
    "    display(df)\n",
    "except FileNotFoundError:\n",
    "    print(\"benchmark_results.json not found. Make sure the previous step ran successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Visualization\n",
    "\n",
    "Now, let's plot the results to better visualize the performance differences. We'll create a line plot showing execution time versus the number of vertices for each implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Melt the dataframe to make it suitable for seaborn\n",
    "    df_melted = df.melt(id_vars=['vertices'], var_name='Implementation', value_name='Execution Time (s)')\n",
    "    df_melted = df_melted.dropna()\n",
    "\n",
    "    sns.lineplot(data=df_melted, x='vertices', y='Execution Time (s)', hue='Implementation', marker='o', ax=ax)\n",
    "\n",
    "    ax.set_title('Bellman-Ford Performance Comparison', fontsize=16)\n",
    "    ax.set_xlabel('Number of Vertices', fontsize=12)\n",
    "    ax.set_ylabel('Execution Time (s)', fontsize=12)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend(title='Implementation')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "*(This is a placeholder for the analysis. The actual analysis will be written after running the notebook in a GPU-enabled environment.)*\n",
    "\n",
    "From the plot, we can draw several conclusions:\n",
    "\n",
    "- **Serial:** As expected, the serial implementation is the slowest. Its execution time grows rapidly with the number of vertices.\n",
    "- **OpenMP:** The OpenMP version provides a significant speedup over the serial version by utilizing multiple CPU cores. However, its performance is still limited by the number of available cores.\n",
    "- **CUDA:** For larger graphs, the CUDA implementation should demonstrate a dramatic performance improvement. The massive parallelism of the GPU allows it to process a large number of edges simultaneously. For smaller graphs, the overhead of transferring data to and from the GPU might make it slower than the CPU-based versions.\n",
    "- **Hybrid:** The hybrid approach aims to get the best of both worlds. It can be particularly effective for certain graph structures and problem sizes, but its performance depends heavily on the CPU-GPU workload split."
   ]
  },
  {
   "cell__type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "This analysis demonstrates the power of high-performance computing techniques for accelerating the Bellman-Ford algorithm. While the serial version is simple to implement, it does not scale well. OpenMP provides a good performance boost on multi-core CPUs. For maximum performance on large graphs, the CUDA implementation is the clear winner, showcasing the massive parallel processing capabilities of modern GPUs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
