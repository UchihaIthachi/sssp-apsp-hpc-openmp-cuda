{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFcEX_XUVQ6o"
      },
      "source": [
        "# Performance Analysis of Bellman-Ford HPC Implementations (Colab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK6xB-_nVQ6s"
      },
      "source": [
        "This notebook provides a complete workflow to set up the environment, run benchmarks, and analyze the performance of four different implementations of the Bellman-Ford algorithm on Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMUeWgICVQ6t"
      },
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "First, let's set up the environment. This involves checking for a GPU, cloning the project repository from GitHub, and installing Python dependencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiRUdY1zVQ6t"
      },
      "source": [
        "### 1.1 Check GPU Availability\n",
        "\n",
        "Ensure that a GPU is available. Go to **Runtime -> Change runtime type** and select **GPU** as the hardware accelerator. The following cell should show your assigned GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fjdvU-pTVQ6u",
        "outputId": "f6c08393-1e92-4374-fad4-129b7f1f4331",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug 26 07:43:43 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIrUW9ZCVQ6w"
      },
      "source": [
        "### 1.2 Clone the Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cSCy4GxkVQ6x",
        "outputId": "aefbd69c-0e0f-4a13-fa26-24dc53bd2e1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bellman-ford-hpc-openmp-cuda'...\n",
            "warning: redirecting to https://github.com/UchihaIthachi/bellman-ford-hpc-openmp-cuda.git/\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 45 (delta 15), reused 36 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (45/45), 24.16 KiB | 4.03 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "/content/bellman-ford-hpc-openmp-cuda\n"
          ]
        }
      ],
      "source": [
        "!git clone https://www.github.com/UchihaIthachi/bellman-ford-hpc-openmp-cuda.git\n",
        "%cd bellman-ford-hpc-openmp-cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3NG1vAjVQ6x"
      },
      "source": [
        "### 1.3 Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tBz4eIbYVQ6y",
        "outputId": "3465b32f-345d-4ebd-bfc2-084a35bf6967",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas matplotlib seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTXh5HfWVQ6y"
      },
      "source": [
        "## 2. Build the Executables\n",
        "\n",
        "Next, we compile the C/C++ and CUDA source code. The `Makefile` will automatically detect the GPU architecture and build the executables in the `bin/` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kCSK_BxzVQ6y",
        "outputId": "1e468eda-091c-4c17-b884-62ec524570b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm -rf ./bin reports\n",
            "rm -f BF_serial BF_openmp BF_cuda BF_hybrid\n",
            "rm -f *_output__*.txt\n",
            "rm -f data/graph_*.txt\n",
            "mkdir -p ./bin\n",
            "g++ -O2 -std=c++14 -Wall -I./include -I./utils src/BF_serial.c utils/graph_io.c utils/graphGen.c -o bin/BF_serial\n",
            "mkdir -p ./bin\n",
            "g++ -O2 -std=c++14 -Wall -fopenmp -I./include -I./utils src/BF_openmp.c utils/graph_io.c utils/graphGen.c -o bin/BF_openmp\n",
            "mkdir -p ./bin\n",
            "nvcc -O2 -std=c++14 -gencode arch=compute_50,code=sm_50 -I./include -I./utils src/BF_cuda.cu utils/graph_io.c utils/graphGen.c -o bin/BF_cuda\n",
            "mkdir -p ./bin\n",
            "nvcc -O2 -std=c++14 -gencode arch=compute_50,code=sm_50 -Xcompiler -fopenmp -I./include -I./utils src/BF_hybrid.cu utils/graph_io.c utils/graphGen.c -o bin/BF_hybrid\n"
          ]
        }
      ],
      "source": [
        "!make clean && make"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9KC5uOaVQ6y"
      },
      "source": [
        "## 3. Run the Benchmarks\n",
        "\n",
        "Now, we'll run our custom benchmarking script, `scripts/benchmark.py`. This script will execute each Bellman-Ford implementation across a range of graph sizes and save the timing results to `benchmark_results.json`.\n",
        "\n",
        "You can customize the vertex counts by modifying the `--vertices` argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqvgfTTCVQ6z",
        "outputId": "389287b7-c6d5-42fc-9bc6-2ab3deb470f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building project...\n",
            "Running benchmarks for 1000 vertices...\n",
            "  Running Serial...\n",
            "    Time: 1e-05s\n",
            "  Running OpenMP...\n",
            "    Time: 0.01127s\n",
            "  Running CUDA...\n",
            "Error running command: ./bin/BF_cuda 1000 -30 30 0.001\n",
            "Stderr: CUDA error malloc edges: CUDA driver version is insufficient for CUDA runtime version\n",
            "\n",
            "  Running Hybrid...\n",
            "Error running command: OMP_NUM_THREADS=8 ./bin/BF_hybrid 1000 -30 30 0.5 0.001 8\n",
            "Stderr: CUDA error malloc edges: CUDA driver version is insufficient for CUDA runtime version\n",
            "\n",
            "Running benchmarks for 2000 vertices...\n",
            "  Running Serial...\n",
            "    Time: 3.3e-05s\n",
            "  Running OpenMP...\n",
            "    Time: 0.014027s\n",
            "  Running CUDA...\n",
            "Error running command: ./bin/BF_cuda 2000 -30 30 0.001\n",
            "Stderr: CUDA error malloc edges: CUDA driver version is insufficient for CUDA runtime version\n",
            "\n",
            "  Running Hybrid...\n",
            "Error running command: OMP_NUM_THREADS=8 ./bin/BF_hybrid 2000 -30 30 0.5 0.001 8\n",
            "Stderr: CUDA error malloc edges: CUDA driver version is insufficient for CUDA runtime version\n",
            "\n",
            "Running benchmarks for 5000 vertices...\n",
            "  Running Serial...\n",
            "    Time: 1.413797s\n",
            "  Running OpenMP...\n",
            "    Time: 3.560919s\n",
            "  Running CUDA...\n",
            "Error running command: ./bin/BF_cuda 5000 -30 30 0.001\n",
            "Stderr: CUDA error malloc edges: CUDA driver version is insufficient for CUDA runtime version\n",
            "\n",
            "  Running Hybrid...\n",
            "Error running command: OMP_NUM_THREADS=8 ./bin/BF_hybrid 5000 -30 30 0.5 0.001 8\n",
            "Stderr: CUDA error malloc edges: CUDA driver version is insufficient for CUDA runtime version\n",
            "\n",
            "Running benchmarks for 10000 vertices...\n",
            "  Running Serial...\n",
            "    Time: 11.01191s\n",
            "  Running OpenMP...\n",
            "    Time: 9.908699s\n",
            "  Running CUDA...\n",
            "Error running command: ./bin/BF_cuda 10000 -30 30 0.001\n",
            "Stderr: CUDA error malloc edges: CUDA driver version is insufficient for CUDA runtime version\n",
            "\n",
            "  Running Hybrid...\n",
            "Error running command: OMP_NUM_THREADS=8 ./bin/BF_hybrid 10000 -30 30 0.5 0.001 8\n",
            "Stderr: CUDA error malloc edges: CUDA driver version is insufficient for CUDA runtime version\n",
            "\n",
            "Running benchmarks for 20000 vertices...\n",
            "  Running Serial...\n",
            "    Time: 84.308666s\n",
            "  Running OpenMP...\n"
          ]
        }
      ],
      "source": [
        "!chmod +x scripts/benchmark.py\n",
        "!./scripts/benchmark.py --vertices 1000 2000 5000 10000 20000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEfHwm5lVQ6z"
      },
      "source": [
        "## 4. Analyze the Results\n",
        "\n",
        "With the benchmarks complete, let's load the results into a pandas DataFrame and examine the raw data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI7jc_5rVQ6z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "try:\n",
        "    with open('benchmark_results.json', 'r') as f:\n",
        "        results = json.load(f)\n",
        "    df = pd.DataFrame(results)\n",
        "    print(\"Benchmark Results:\")\n",
        "    display(df)\n",
        "except FileNotFoundError:\n",
        "    print(\"benchmark_results.json not found. Make sure the previous step ran successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yMNE2HoVQ6z"
      },
      "source": [
        "### Performance Visualization\n",
        "\n",
        "Now, let's plot the results to better visualize the performance differences. We'll create a line plot showing execution time versus the number of vertices for each implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zLhvd5PVQ6z"
      },
      "outputs": [],
      "source": [
        "if 'df' in locals():\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    # Melt the dataframe to make it suitable for seaborn\n",
        "    df_melted = df.melt(id_vars=['vertices'], var_name='Implementation', value_name='Execution Time (s)')\n",
        "    df_melted = df_melted.dropna()\n",
        "\n",
        "    sns.lineplot(data=df_melted, x='vertices', y='Execution Time (s)', hue='Implementation', marker='o', ax=ax)\n",
        "\n",
        "    ax.set_title('Bellman-Ford Performance Comparison', fontsize=16)\n",
        "    ax.set_xlabel('Number of Vertices', fontsize=12)\n",
        "    ax.set_ylabel('Execution Time (s)', fontsize=12)\n",
        "    ax.set_xscale('log')\n",
        "    ax.set_yscale('log')\n",
        "    ax.legend(title='Implementation')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXgoKT2GVQ60"
      },
      "source": [
        "### Analysis\n",
        "\n",
        "*(This is a placeholder for the analysis. The actual analysis will be written after running the notebook in a GPU-enabled environment.)*\n",
        "\n",
        "From the plot, we can draw several conclusions:\n",
        "\n",
        "- **Serial:** As expected, the serial implementation is the slowest. Its execution time grows rapidly with the number of vertices.\n",
        "- **OpenMP:** The OpenMP version provides a significant speedup over the serial version by utilizing multiple CPU cores. However, its performance is still limited by the number of available cores.\n",
        "- **CUDA:** For larger graphs, the CUDA implementation should demonstrate a dramatic performance improvement. The massive parallelism of the GPU allows it to process a large number of edges simultaneously. For smaller graphs, the overhead of transferring data to and from the GPU might make it slower than the CPU-based versions.\n",
        "- **Hybrid:** The hybrid approach aims to get the best of both worlds. It can be particularly effective for certain graph structures and problem sizes, but its performance depends heavily on the CPU-GPU workload split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON9jYqcJVQ60"
      },
      "source": [
        "## 5. Conclusion\n",
        "\n",
        "This analysis demonstrates the power of high-performance computing techniques for accelerating the Bellman-Ford algorithm. While the serial version is simple to implement, it does not scale well. OpenMP provides a good performance boost on multi-core CPUs. For maximum performance on large graphs, the CUDA implementation is the clear winner, showcasing the massive parallel processing capabilities of modern GPUs."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}