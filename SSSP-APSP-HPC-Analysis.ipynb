{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "new-title"
      },
      "source": [
        "# SSSP/APSP HPC: A Comparative Performance Analysis (Colab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "new-intro"
      },
      "source": [
        "This notebook provides a complete workflow to set up the environment, build the project, run benchmarks, and analyze the performance of multiple shortest-path algorithms and their HPC variants."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "new-toc"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "1. [Environment Setup](#env-setup)\n",
        "2. [Algorithm Primer](#primer)\n",
        "3. [Build Executables](#build)\n",
        "4. [Run Benchmarks](#benchmarks)\n",
        "5. [Analyze Results](#analysis)\n",
        "6. [Speedup Analysis](#speedups)\n",
        "7. [Suggestions for Further Improvement](#suggestions)\n",
        "8. [Performance Visualization](#plots)\n",
        "9. [License & Attribution](#license)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "env-setup"
      },
      "source": [
        "## 1. Environment Setup <a name=\"env-setup\"></a>\n",
        "\n",
        "First, let's set up the environment. This involves checking for a GPU, cloning the project repository, and installing pinned Python dependencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Check GPU Availability\n",
        "\n",
        "Ensure a GPU is available. Go to **Runtime -> Change runtime type** and select a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Clone Repository & Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://www.github.com/UchihaIthachi/bellman-ford-hpc-openmp-cuda.git\n",
        "%cd bellman-ford-hpc-openmp-cuda\n",
        "\n",
        "print(\"Current commit hash:\")\n",
        "!git rev-parse HEAD\n",
        "\n",
        "%pip install -q pandas==2.0.3 matplotlib==3.7.1 seaborn==0.12.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "primer"
      },
      "source": [
        "## 2. Algorithm Primer <a name=\"primer\"></a>\n",
        "\n",
        "- **Dijkstra's Algorithm:** Finds the shortest path in a graph with non-negative edge weights; it's fast (O(E log V)) but cannot handle negative weights.\n",
        "- **Bellman-Ford Algorithm:** Finds the shortest path in a graph that may contain negative edge weights; it's slower (O(VE)) but more versatile.\n",
        "- **Floyd-Warshall Algorithm:** Finds all-pairs shortest paths in a weighted graph; its O(V^3) complexity makes it suitable for dense graphs.\n",
        "- **Johnson's Algorithm:** Finds all-pairs shortest paths, outperforming Floyd-Warshall on sparse graphs (O(VE + V^2 log V)) by using Bellman-Ford and Dijkstra as subroutines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "build"
      },
      "source": [
        "## 3. Build the Executables <a name=\"build\"></a>\n",
        "\n",
        "Next, we compile the source code. The logic below detects the GPU architecture and sets environment variables to ensure a reproducible and optimized build."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess, os\n",
        "\n",
        "def detect_sm():\n",
        "    try:\n",
        "        name = subprocess.check_output(\n",
        "            \"nvidia-smi --query-gpu=name --format=csv,noheader\",\n",
        "            shell=True, text=True).strip()\n",
        "        if \"T4\" in name: return \"sm_75\"\n",
        "        if \"V100\" in name: return \"sm_70\"\n",
        "        if \"A100\" in name: return \"sm_80\"\n",
        "        if \"L4\" in name or \"4090\" in name: return \"sm_89\"\n",
        "    except Exception:\n",
        "        pass\n",
        "    return \"sm_75\"  # safe default for Colab T4\n",
        "\n",
        "os.environ[\"GPU_ARCH\"] = detect_sm()\n",
        "print(\"GPU_ARCH =\", os.environ[\"GPU_ARCH\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil, os\n",
        "if shutil.which(\"nvcc\") is None:\n",
        "    os.environ[\"DISABLE_CUDA\"] = \"1\"\n",
        "    print(\"nvcc not found â†’ CUDA targets will be skipped.\")\n",
        "else:\n",
        "    print(\"nvcc found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, multiprocessing\n",
        "os.environ[\"OMP_NUM_THREADS\"] = str(multiprocessing.cpu_count())\n",
        "os.environ[\"OMP_PROC_BIND\"] = \"close\"\n",
        "os.environ[\"OMP_PLACES\"] = \"cores\"\n",
        "print(f\"OpenMP configured for {os.environ['OMP_NUM_THREADS']} threads.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!make clean && make all GPU_ARCH=$GPU_ARCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "benchmarks"
      },
      "source": [
        "## 4. Run the Benchmarks <a name=\"benchmarks\"></a>\n",
        "\n",
        "Now we run the benchmarks. We use helper functions to construct valid command-line arguments for each executable and to run each command multiple times, taking the median for stable results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess, re, statistics, os\n",
        "\n",
        "def run_command(command, timeout=300):\n",
        "    try:\n",
        "        print(f\"  Executing: {command}\")\n",
        "        return subprocess.run(command, shell=True, capture_output=True, text=True, check=True, timeout=timeout).stdout\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"    Error:\", e.stderr.strip())\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"    Error: timeout\")\n",
        "    return None\n",
        "\n",
        "def parse_time(output):\n",
        "    if not output: return None\n",
        "    m = re.search(r\"time:\\s*([0-9]*\\.?[0-9]+)\\s*(ms|s|sec|seconds)?\", output, re.I)\n",
        "    if not m: return None\n",
        "    val = float(m.group(1))\n",
        "    unit = (m.group(2) or \"s\").lower()\n",
        "    if unit.startswith(\"ms\"): val /= 1000.0\n",
        "    return val\n",
        "\n",
        "def time_exe(cmd, warmups=1, runs=3):\n",
        "    if cmd is None: return None\n",
        "    for _ in range(warmups):\n",
        "        _ = run_command(cmd)\n",
        "    samples = []\n",
        "    for _ in range(runs):\n",
        "        t = parse_time(run_command(cmd))\n",
        "        if t is not None: samples.append(t)\n",
        "    return statistics.median(samples) if samples else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def build_cmd(exe, v, min_w, max_w, density, threads, split_ratio):\n",
        "    path = os.path.join(\"bin\", exe)\n",
        "    if not os.path.exists(path): return None\n",
        "\n",
        "    if exe.startswith(\"dijkstra\"):\n",
        "        args = [str(v), str(max(min_w,0)+1), str(max_w)]\n",
        "    elif exe.startswith(\"BF\"):\n",
        "        args = [str(v), str(min_w), str(max_w)]\n",
        "    elif exe.startswith(\"floyd\"):\n",
        "        args = [str(v), str(min_w), str(max_w)]\n",
        "    elif exe.startswith(\"johnson\"):\n",
        "        args = [str(v), str(min_w), str(max_w)]\n",
        "    else:\n",
        "        args = [str(v), str(min_w), str(max_w)]\n",
        "\n",
        "    if \"hybrid\" in exe:\n",
        "        args.insert(3, str(split_ratio))\n",
        "    if (\"openmp\" in exe) or (\"hybrid\" in exe):\n",
        "        args.append(str(threads))\n",
        "\n",
        "    return \" \".join([path] + args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "benchmark_params = {\n",
        "    'sssp_vertices': [500, 1000, 2000, 4000],\n",
        "    'apsp_vertices': [50, 100, 200, 300],\n",
        "    'min_w': -10,\n",
        "    'max_w': 50,\n",
        "    'density': 0.1, # Note: density is not used by the new build_cmd\n",
        "    'threads': int(os.environ.get(\"OMP_NUM_THREADS\", 4)),\n",
        "    'split_ratio': 0.5\n",
        "}\n",
        "\n",
        "executables = {\n",
        "    'sssp': ['dijkstra_serial', 'dijkstra_openmp', 'dijkstra_cuda', 'dijkstra_hybrid', 'BF_serial', 'BF_openmp', 'BF_cuda', 'BF_hybrid'],\n",
        "    'apsp': ['floyd_serial', 'floyd_openmp', 'floyd_cuda', 'johnson_serial', 'johnson_openmp', 'johnson_cuda', 'johnson_hybrid']\n",
        "}\n",
        "\n",
        "all_results = []\n",
        "for group, vertices_list in [('sssp', benchmark_params['sssp_vertices']), ('apsp', benchmark_params['apsp_vertices'])]:\n",
        "    for v in vertices_list:\n",
        "        print(f\"\\nRunning {group.upper()} benchmarks for {v} vertices...\")\n",
        "        result_row = {'vertices': v, 'group': group}\n",
        "        for exe in executables[group]:\n",
        "            cmd = build_cmd(exe, v, **benchmark_params)\n",
        "            time = time_exe(cmd)\n",
        "            result_row[exe] = time\n",
        "            if time is not None:\n",
        "                print(f\"    {exe}: {time:.6f}s\")\n",
        "        all_results.append(result_row)\n",
        "\n",
        "df = pd.DataFrame(all_results)\n",
        "df.to_json(\"benchmark_results.json\", orient='records', indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "analysis"
      },
      "source": [
        "## 5. Analyze the Results <a name=\"analysis\"></a>\n",
        "\n",
        "With the benchmarks complete, we load the results and display them in separate, clean tables for SSSP and APSP algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np\n",
        "\n",
        "def _cols_with_prefix(df, prefixes):\n",
        "    return [c for c in df.columns if any(c.startswith(p) for p in prefixes)]\n",
        "\n",
        "df = pd.read_json('benchmark_results.json')\n",
        "\n",
        "sssp_cols = _cols_with_prefix(df, ('dijkstra_', 'BF_'))\n",
        "apsp_cols = _cols_with_prefix(df, ('floyd_', 'johnson_'))\n",
        "\n",
        "df_sssp = (df[df['group']=='sssp'][['vertices']+sssp_cols]\n",
        "           .dropna(axis=1, how='all')\n",
        "           .set_index('vertices').sort_index())\n",
        "\n",
        "df_apsp = (df[df['group']=='apsp'][['vertices']+apsp_cols]\n",
        "           .dropna(axis=1, how='all')\n",
        "           .set_index('vertices').sort_index())\n",
        "\n",
        "print(\"SSSP Benchmark Results (Time in seconds):\")\n",
        "display(df_sssp)\n",
        "print(\"\\nAPSP Benchmark Results (Time in seconds):\")\n",
        "display(df_apsp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "speedups"
      },
      "source": [
        "## 6. Speedup Analysis <a name=\"speedups\"></a>\n",
        "\n",
        "Next, we calculate the speedup of parallel versions relative to their serial counterparts. Speedup is `Time_Serial / Time_Parallel`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np\n",
        "\n",
        "def speedup_frame(df_family, bases=(\"dijkstra\",\"BF\")):\n",
        "    out = pd.DataFrame(index=df_family.index)\n",
        "    for base in bases:\n",
        "        s = df_family.get(f\"{base}_serial\")\n",
        "        if s is None: continue\n",
        "        for var in (\"openmp\",\"cuda\",\"hybrid\"):\n",
        "            p = df_family.get(f\"{base}_{var}\")\n",
        "            if p is None: continue\n",
        "            sp = (s / p).replace([np.inf,-np.inf], np.nan)\n",
        "            out[f\"{base}_{var}_speedup\"] = sp\n",
        "    return out\n",
        "\n",
        "df_sssp_speedup = speedup_frame(df_sssp, (\"dijkstra\",\"BF\"))\n",
        "df_apsp_speedup = speedup_frame(df_apsp, (\"floyd\",\"johnson\"))\n",
        "\n",
        "print(\"SSSP Speedup (vs. Serial):\"); display(df_sssp_speedup)\n",
        "print(\"\\nAPSP Speedup (vs. Serial):\"); display(df_apsp_speedup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GPU Utilization Monitor\n",
        "\n",
        "Run this cell while a CUDA benchmark is active in another cell to see live GPU utilization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time, subprocess\n",
        "for _ in range(15):\n",
        "    try:\n",
        "        print(subprocess.check_output(\n",
        "            \"nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader,nounits\",\n",
        "            shell=True, text=True).strip())\n",
        "    except Exception as e:\n",
        "        print(\"nvidia-smi error:\", e)\n",
        "    time.sleep(0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save CSV Artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"benchmark_results_raw.csv\", index=False)\n",
        "df_sssp_speedup.to_csv(\"benchmark_speedup_sssp.csv\")\n",
        "df_apsp_speedup.to_csv(\"benchmark_speedup_apsp.csv\")\n",
        "print(\"Saved: benchmark_results_raw.csv, benchmark_speedup_sssp.csv, benchmark_speedup_apsp.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suggestions"
      },
      "source": [
        "## 7. Suggestions for Further Improvement <a name=\"suggestions\"></a>\n",
        "\n",
        "- **Scalability Analysis:** Run benchmarks with varying numbers of OpenMP threads or across different graph densities.\n",
        "- **Profiling:** Use tools like `nvprof` or `nsys` to identify performance bottlenecks in CUDA kernels or data transfers.\n",
        "- **Workload Analysis:** Benchmark using real-world graph datasets to see how performance translates from synthetic data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plots"
      },
      "source": [
        "## 8. Performance Visualization <a name=\"plots\"></a>\n",
        "\n",
        "Finally, we plot the results to visualize performance differences and speedups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "if 'df' in locals():\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "    fig.suptitle('Algorithm Performance Comparison', fontsize=18)\n",
        "\n",
        "    # SSSP Algorithms\n",
        "    df_sssp_melted = df_sssp.reset_index().melt(id_vars=['vertices'], var_name='Algorithm', value_name='Time (s)').dropna()\n",
        "    sns.lineplot(data=df_sssp_melted, x='vertices', y='Time (s)', hue='Algorithm', marker='o', ax=ax1)\n",
        "    ax1.set_title('SSSP Algorithm Performance', fontsize=16)\n",
        "    ax1.set_yscale('log')\n",
        "\n",
        "    # APSP Algorithms\n",
        "    df_apsp_melted = df_apsp.reset_index().melt(id_vars=['vertices'], var_name='Algorithm', value_name='Time (s)').dropna()\n",
        "    sns.lineplot(data=df_apsp_melted, x='vertices', y='Time (s)', hue='Algorithm', marker='o', ax=ax2)\n",
        "    ax2.set_title('APSP Algorithm Performance', fontsize=16)\n",
        "    ax2.set_yscale('log')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'df_sssp_speedup' in locals() and 'df_apsp_speedup' in locals():\n",
        "    sssp_melted = df_sssp_speedup.reset_index().melt(id_vars=['vertices'], var_name='Algorithm', value_name='Speedup').dropna()\n",
        "    apsp_melted = df_apsp_speedup.reset_index().melt(id_vars=['vertices'], var_name='Algorithm', value_name='Speedup').dropna()\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(18, 16))\n",
        "    fig.suptitle('HPC Speedup vs. Serial', fontsize=18)\n",
        "    \n",
        "    sns.barplot(data=sssp_melted, x='vertices', y='Speedup', hue='Algorithm', ax=ax1)\n",
        "    ax1.set_title('SSSP Algorithm Speedup')\n",
        "    ax1.axhline(1, color='grey', linestyle='--')\n",
        "    \n",
        "    sns.barplot(data=apsp_melted, x='vertices', y='Speedup', hue='Algorithm', ax=ax2)\n",
        "    ax2.set_title('APSP Algorithm Speedup')\n",
        "    ax2.axhline(1, color='grey', linestyle='--')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "license"
      },
      "source": [
        "## 9. License & Attribution <a name=\"license\"></a>\n",
        "\n",
        "This project is licensed under the MIT License. See the `LICENSE` file in the repository for details."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
