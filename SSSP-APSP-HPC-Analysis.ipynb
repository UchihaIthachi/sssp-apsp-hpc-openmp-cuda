{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFcEX_XUVQ6o"
      },
      "source": [
        "# SSSP/APSP HPC: A Comparative Performance Analysis (Colab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK6xB-_nVQ6s"
      },
      "source": [
        "This notebook provides a complete workflow to set up the environment, build the project, run benchmarks, and analyze the performance of multiple shortest-path algorithms (Dijkstra, Bellman-Ford, Floyd-Warshall, Johnson's) and their HPC variants (Serial, OpenMP, CUDA, Hybrid)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMUeWgICVQ6t"
      },
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "First, let's set up the environment. This involves checking for a GPU, cloning the project repository from GitHub, and installing Python dependencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiRUdY1zVQ6t"
      },
      "source": [
        "### 1.1 Check GPU Availability\n",
        "\n",
        "Ensure that a GPU is available for the CUDA/hybrid builds. Go to **Runtime -> Change runtime type** and select **GPU** as the hardware accelerator. The following cell should show your assigned GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjdvU-pTVQ6u"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIrUW9ZCVQ6w"
      },
      "source": [
        "### 1.2 Clone the Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSCy4GxkVQ6x"
      },
      "outputs": [],
      "source": [
        "!git clone https://www.github.com/UchihaIthachi/bellman-ford-hpc-openmp-cuda.git\n",
        "%cd bellman-ford-hpc-openmp-cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3NG1vAjVQ6x"
      },
      "source": [
        "### 1.3 Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBz4eIbYVQ6y"
      },
      "outputs": [],
      "source": [
        "%pip install pandas matplotlib seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTXh5HfWVQ6y"
      },
      "source": [
        "## 2. Build the Executables\n",
        "\n",
        "Next, we compile all the C/C++ and CUDA source code. The new `Makefile` will automatically build all targets and place them in the `bin/` directory. If `nvcc` is not found, CUDA-based targets will be gracefully skipped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCSK_BxzVQ6y"
      },
      "outputs": [],
      "source": [
        "!make clean && make all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9KC5uOaVQ6y"
      },
      "source": [
        "## 3. Run the Benchmarks\n",
        "\n",
        "Now, we'll run a series of benchmarks directly from the notebook. The code below will execute each compiled binary across a range of graph sizes and collect the timing results into a pandas DataFrame.\n",
        "\n",
        "You can customize the vertex counts and other parameters in the `benchmark_params` dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqvgfTTCVQ6z"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import re\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def run_command(command):\n",
        "    try:\n",
        "        print(f\"  Executing: {command}\")\n",
        "        return subprocess.run(command, shell=True, capture_output=True, text=True, check=True).stdout\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"    Error running command. Stderr: {e.stderr.strip()}\")\n",
        "        return None\n",
        "\n",
        "def parse_time(output):\n",
        "    match = re.search(r\"time: ([\\d.]+) s\", output)\n",
        "    return float(match.group(1)) if match else None\n",
        "\n",
        "benchmark_params = {\n",
        "    'sssp_vertices': [500, 1000, 2000, 5000],\n",
        "    'apsp_vertices': [50, 100, 200, 400],\n",
        "    'min_w': -10,\n",
        "    'max_w': 50,\n",
        "    'density': 0.1,\n",
        "    'threads': 4,\n",
        "    'split_ratio': 0.5\n",
        "}\n",
        "\n",
        "executables = {\n",
        "    'sssp': ['dijkstra_serial', 'dijkstra_openmp', 'dijkstra_cuda', 'dijkstra_hybrid', 'BF_serial', 'BF_openmp', 'BF_cuda', 'BF_hybrid'],\n",
        "    'apsp': ['floyd_serial', 'floyd_openmp', 'floyd_cuda', 'johnson_serial', 'johnson_openmp', 'johnson_cuda', 'johnson_hybrid']\n",
        "}\n",
        "\n",
        "all_results = []\n",
        "for group, vertices_list in [('sssp', benchmark_params['sssp_vertices']), ('apsp', benchmark_params['apsp_vertices'])]:\n",
        "    for v in vertices_list:\n",
        "        print(f\"\\nRunning {group.upper()} benchmarks for {v} vertices...\")\n",
        "        result_row = {'vertices': v, 'group': group}\n",
        "        for exe in executables[group]:\n",
        "            path = f\"./bin/{exe}\"\n",
        "            if not os.path.exists(path):\n",
        "                result_row[exe] = None\n",
        "                continue\n",
        "            \n",
        "            cmd_parts = [path, v, benchmark_params['min_w'], benchmark_params['max_w']]\n",
        "            # Dijkstra requires non-negative weights, so adjust min_w\n",
        "            if 'dijkstra' in exe:\n",
        "                cmd_parts[2] = 1 # Use 1 for min_w\n",
        "            \n",
        "            cmd_parts.append(benchmark_params['density'])\n",
        "            \n",
        "            if 'hybrid' in exe:\n",
        "                 cmd_parts.insert(4, benchmark_params['split_ratio'])\n",
        "            \n",
        "            if 'openmp' in exe or 'hybrid' in exe:\n",
        "                cmd_parts.append(benchmark_params['threads'])\n",
        "            \n",
        "            cmd = ' '.join(map(str, cmd_parts))\n",
        "            output = run_command(cmd)\n",
        "            \n",
        "            if output:\n",
        "                time = parse_time(output)\n",
        "                result_row[exe] = time\n",
        "                if time is not None:\n",
        "                    print(f\"    {exe}: {time:.6f}s\")\n",
        "            else:\n",
        "                result_row[exe] = None\n",
        "        all_results.append(result_row)\n",
        "\n",
        "df = pd.DataFrame(all_results)\n",
        "df.to_json(\"benchmark_results.json\", orient='records', indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEfHwm5lVQ6z"
      },
      "source": [
        "## 4. Analyze the Results\n",
        "\n",
        "With the benchmarks complete, let's load the results into a pandas DataFrame and examine the raw data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI7jc_5rVQ6z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    df = pd.read_json('benchmark_results.json')\n",
        "    print(\"Benchmark Results:\")\n",
        "    display(df.set_index('vertices'))\n",
        "except FileNotFoundError:\n",
        "    print(\"benchmark_results.json not found. Make sure the previous step ran successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yMNE2HoVQ6z"
      },
      "source": [
        "### Performance Visualization\n",
        "\n",
        "Now, let's plot the results to visualize the performance differences. We will create separate plots for SSSP and APSP algorithms, as their runtimes are on different scales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zLhvd5PVQ6z"
      },
      "outputs": [],
      "source": [
        "if 'df' in locals():\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "    fig.suptitle('Algorithm Performance Comparison', fontsize=18)\n",
        "\n",
        "    # SSSP Algorithms\n",
        "    df_sssp = df[df['group'] == 'sssp'].drop(columns='group').melt(id_vars=['vertices'], var_name='Algorithm', value_name='Time (s)').dropna()\n",
        "    sns.lineplot(data=df_sssp, x='vertices', y='Time (s)', hue='Algorithm', marker='o', ax=ax1)\n",
        "    ax1.set_title('SSSP Algorithm Performance', fontsize=16)\n",
        "    ax1.set_xlabel('Number of Vertices', fontsize=12)\n",
        "    ax1.set_ylabel('Execution Time (s) [Log Scale]', fontsize=12)\n",
        "    ax1.set_yscale('log')\n",
        "    ax1.legend(title='SSSP Variants')\n",
        "\n",
        "    # APSP Algorithms\n",
        "    df_apsp = df[df['group'] == 'apsp'].drop(columns='group').melt(id_vars=['vertices'], var_name='Algorithm', value_name='Time (s)').dropna()\n",
        "    sns.lineplot(data=df_apsp, x='vertices', y='Time (s)', hue='Algorithm', marker='o', ax=ax2)\n",
        "    ax2.set_title('APSP Algorithm Performance', fontsize=16)\n",
        "    ax2.set_xlabel('Number of Vertices', fontsize=12)\n",
        "    ax2.set_ylabel('Execution Time (s) [Log Scale]', fontsize=12)\n",
        "    ax2.set_yscale('log')\n",
        "    ax2.legend(title='APSP Variants')\n",
        "    \n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXgoKT2GVQ60"
      },
      "source": [
        "### Analysis\n",
        "\n",
        "From the plots, we can draw several conclusions:\n",
        "\n",
        "- **SSSP (Dijkstra vs. Bellman-Ford):** Dijkstra's algorithm consistently outperforms Bellman-Ford for graphs with non-negative weights. This is expected due to their complexity differences (O(E log V) or O(V^2) for Dijkstra vs. O(VE) for Bellman-Ford). Bellman-Ford's advantage is its ability to handle negative weights, which comes at a performance cost.\n",
        "\n",
        "- **APSP (Floyd-Warshall vs. Johnson's):** For dense graphs (as generated here), Floyd-Warshall's O(V^3) complexity can be competitive. Johnson's algorithm, with a complexity of O(VE + V^2 log V), is typically better suited for sparse graphs. The benchmark results here should illustrate this trade-off.\n",
        "\n",
        "- **Parallelism (OpenMP/CUDA):** The parallel implementations (OpenMP, CUDA) show significant speedups over their serial counterparts, especially for larger graphs. The massive parallelism of the GPU should make the CUDA variants the fastest for large problem sizes, though the overhead of data transfer can impact performance on smaller graphs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON9jYqcJVQ60"
      },
      "source": [
        "## 5. Conclusion\n",
        "\n",
        "This analysis demonstrates the performance characteristics of various SSSP and APSP algorithms and their HPC implementations. The choice of algorithm depends heavily on the graph's properties (e.g., presence of negative weights, density), while the choice of implementation depends on the available hardware and the desired level of performance. For maximum speed on large-scale problems, GPU-accelerated solutions using CUDA are highly effective."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}