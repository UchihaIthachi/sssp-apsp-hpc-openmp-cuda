{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Bellman-Ford SSSP Benchmark\n",
    "\n",
    "This notebook benchmarks the following variants of the Bellman-Ford algorithm for Single-Source Shortest Path (SSSP):\n",
    "- `BF_serial`\n",
    "- `BF_openmp`\n",
    "- `BF_cuda`\n",
    "- `BF_hybrid`\n",
    "\n",
    "Bellman-Ford is suitable for graphs that may contain negative edge weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Copy and paste the utility functions from `00_setup_build.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, statistics, re, os, json, time, pandas as pd\n",
    "\n",
    "def run_command(cmd, timeout=300):\n",
    "    try:\n",
    "        print(\"  >\", cmd)\n",
    "        return subprocess.run(cmd, shell=True, capture_output=True,\n",
    "                             text=True, check=True, timeout=timeout).stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"    stderr:\", e.stderr.strip())\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"    timeout\")\n",
    "    return None\n",
    "\n",
    "def parse_time(out):\n",
    "    if not out: return None\n",
    "    m = re.search(r\"time:\\s*([0-9]*\\\\.?[0-9]+)\\\\s*(ms|s|sec|seconds)?\", out, re.I)\n",
    "    if not m: return None\n",
    "    val = float(m.group(1)); unit = (m.group(2) or \"s\").lower()\n",
    "    return val/1000.0 if unit.startswith(\"ms\") else val\n",
    "\n",
    "def time_exe(cmd, warmups=1, runs=3):\n",
    "    if not cmd: return None\n",
    "    for _ in range(warmups): _ = run_command(cmd)\n",
    "    samples = []\n",
    "    for _ in range(runs):\n",
    "        t = parse_time(run_command(cmd))\n",
    "        if t is not None: samples.append(t)\n",
    "    return statistics.median(samples) if samples else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown **Dataset Selection** (set `use_real_data` to toggle)\n",
    "use_real_data = False  #@param {type:\"boolean\"}\n",
    "real_graph_url = \"https://raw.githubusercontent.com/networkrepository/NRG/edge_list/small_graph.edgelist\" \n",
    "\n",
    "if use_real_data:\n",
    "    import os, requests\n",
    "    graph_path = \"graph.txt\"\n",
    "    if not os.path.exists(graph_path):\n",
    "        try:\n",
    "            resp = requests.get(real_graph_url)\n",
    "            resp.raise_for_status()\n",
    "            with open(graph_path, \"w\") as f:\n",
    "                f.write(resp.text)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not download dataset: {e}\")\n",
    "            use_real_data = False\n",
    "    if use_real_data:\n",
    "        print(\"Using real dataset for Bellman-Ford.\")\n",
    "else:\n",
    "    print(\"Using synthetic random graphs for Bellman-Ford.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Benchmark Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "form"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown ### Benchmark Parameters (BF SSSP)\n",
    "V_list = \"500,1000,2000,5000\"  #@param {type:\"string\"}\n",
    "min_w = -30                    #@param {type:\"integer\"}\n",
    "max_w = 30                     #@param {type:\"integer\"}\n",
    "density = 0.1                  #@param {type:\"number\"}\n",
    "threads = 8                    #@param {type:\"integer\"}\n",
    "split_ratio = 0.5              #@param {type:\"number\"}\n",
    "\n",
    "V_list = [int(x) for x in V_list.split(\",\")]\n",
    "executables = ['BF_serial','BF_openmp','BF_cuda','BF_hybrid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithmic Variant: Frontier Optimization\n",
    "\n",
    "The classic Bellman-Ford algorithm relaxes all |E| edges in each of its |V|-1 iterations. This can be inefficient, as only the vertices whose distances were updated in the previous iteration can relax their neighbors in the current iteration. A common optimization is to maintain a *frontier* of these active vertices.\n",
    "\n",
    "**How it works:**\n",
    "1. Initialize a `current_frontier` set containing only the source vertex.\n",
    "2. In each iteration, only relax the outgoing edges from vertices in the `current_frontier`.\n",
    "3. If a relaxation updates the distance to a vertex `v`, add `v` to the `next_frontier`.\n",
    "4. If `next_frontier` is empty after an iteration, the algorithm can terminate early.\n",
    "5. Set `current_frontier = next_frontier` and repeat.\n",
    "\n",
    "This approach significantly reduces redundant work on many graphs, especially sparse ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-code illustration of frontier-based Bellman-Ford\n",
    "def bellman_ford_frontier(graph, source):\n",
    "    dist = [float('inf')] * graph.V\n",
    "    dist[source] = 0\n",
    "    current_frontier = {source}\n",
    "    for i in range(graph.V - 1):  # at most V-1 iterations\n",
    "        next_frontier = set()\n",
    "        # Relax only edges from current frontier\n",
    "        for u in current_frontier:\n",
    "            for v, w in graph.neighbors(u):\n",
    "                if dist[u] + w < dist[v]:\n",
    "                    dist[v] = dist[u] + w\n",
    "                    next_frontier.add(v)\n",
    "        if not next_frontier:\n",
    "            break  # no updates, can stop early\n",
    "        current_frontier = next_frontier\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Enhancement: Pinned Memory & Streams\n",
    "\n",
    "For large graphs, transferring data between the CPU (host) and GPU (device) can be a bottleneck. We can mitigate this using two techniques:\n",
    "\n",
    "1.  **Pinned (Page-Locked) Memory**: Allocating host memory as 'pinned' allows the GPU to access it directly via Direct Memory Access (DMA), resulting in much faster data transfers. It also enables asynchronous memory copies.\n",
    "2.  **CUDA Streams**: Streams are sequences of operations that execute in order on the GPU. By using multiple streams, we can overlap operations, such as copying data to the GPU while a kernel is already running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlap demo using CuPy (ensure CuPy is installed)\n",
    "try:\n",
    "    import cupy as cp\n",
    "    import numpy as np\n",
    "    \n",
    "    # Prepare data\n",
    "    N = 10**7  # size of data\n",
    "    host_data = np.random.rand(N).astype(np.float32)\n",
    "    d_A = cp.zeros_like(host_data)  # device array\n",
    "    \n",
    "    # Create streams\n",
    "    stream1 = cp.cuda.Stream()\n",
    "    stream2 = cp.cuda.Stream()\n",
    "    \n",
    "    # Async copy H2D and D2H with computation in between\n",
    "    start = cp.cuda.Event(); end = cp.cuda.Event()\n",
    "    start.record()\n",
    "    \n",
    "    with stream1:\n",
    "        d_A.set(host_data)         # H2D copy (async)\n",
    "    with stream2:\n",
    "        d_C = d_A + 5             # A dummy kernel\n",
    "    with stream1:\n",
    "        host_result = d_A.get()    # D2H copy (async)\n",
    "    \n",
    "    end.record()\n",
    "    cp.cuda.stream.get_current_stream().synchronize()\n",
    "    elapsed_ms = cp.cuda.get_elapsed_time(start, end)\n",
    "    print(f\"Overlap demo elapsed time: {elapsed_ms:.2f} ms\")\n",
    "except ImportError:\n",
    "    print(\"CuPy not found, skipping overlap demo. Install with 'pip install cupy-cuda11x' or similar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenMP Schedule Tuning\n",
    "\n",
    "OpenMP's loop scheduling strategy can impact performance. We can experiment with different schedules (`static`, `dynamic`, `guided`) to see which is most effective for the edge relaxation loop in Bellman-Ford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "schedules = [\"static\", \"dynamic\", \"guided\"]\n",
    "schedule_times = {}\n",
    "v_test = 1000 # Use a fixed size for this test\n",
    "\n",
    "for sched in schedules:\n",
    "    os.environ[\"OMP_SCHEDULE\"] = f\"{sched},100\"  # Set schedule and chunk size\n",
    "    cmd = build_cmd_bf(\"BF_openmp\", v=v_test, min_w=min_w, max_w=max_w, \n",
    "                       density=density, threads=threads, split_ratio=split_ratio)\n",
    "    t = time_exe(cmd, warmups=1, runs=3)\n",
    "    schedule_times[sched] = t\n",
    "    if t is not None:\n",
    "        print(f\"Schedule {sched}: {t:.6f}s\")\n",
    "\n",
    "os.environ.pop(\"OMP_SCHEDULE\", None)  # Clean up environment variable\n",
    "\n",
    "# Display results\n",
    "if schedule_times:\n",
    "    best_schedule = min(schedule_times, key=schedule_times.get)\n",
    "    print(f\"\\nBest schedule for V={v_test}: {best_schedule}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Command Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cmd_bf(exe, v, *, min_w, max_w, density, threads, split_ratio):\n",
    "    path = os.path.join(\"bin\", exe)\n",
    "    if not os.path.exists(path): return None\n",
    "    args = [str(v), str(min_w), str(max_w), str(density)]\n",
    "    if \"hybrid\" in exe:\n",
    "        args.insert(3, str(split_ratio))  # V, min, max, split, density\n",
    "    if (\"openmp\" in exe) or (\"hybrid\" in exe):\n",
    "        args.append(str(threads))\n",
    "    return \" \".join([path] + args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for v in V_list:\n",
    "    print(f\"\\nBF for V={v}\")\n",
    "    row = {\"vertices\": v}\n",
    "    for exe in executables:\n",
    "        cmd = build_cmd_bf(exe, v, min_w=min_w, max_w=max_w,\n",
    "                           density=density, threads=threads, split_ratio=split_ratio)\n",
    "        t = time_exe(cmd)\n",
    "        row[exe] = t\n",
    "        if t is not None: print(f\"  {exe}: {t:.6f}s\")\n",
    "    rows.append(row)\n",
    "\n",
    "import pandas as pd\n",
    "df_bf = pd.DataFrame(rows).set_index(\"vertices\").sort_index()\n",
    "df_bf.to_csv(\"bf_times.csv\")\n",
    "df_bf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Speedup Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, seaborn as sns, matplotlib.pyplot as plt\n",
    "base = df_bf['BF_serial']\n",
    "speed = pd.DataFrame({\n",
    "    \"BF_openmp_speedup\": base / df_bf['BF_openmp'],\n",
    "    \"BF_cuda_speedup\":   base / df_bf['BF_cuda'],\n",
    "    \"BF_hybrid_speedup\": base / df_bf['BF_hybrid'],\n",
    "}, index=df_bf.index)\n",
    "\n",
    "display(speed)\n",
    "sns.lineplot(data=speed.reset_index().melt(\"vertices\", var_name=\"variant\", value_name=\"speedup\"),\n",
    "             x=\"vertices\", y=\"speedup\", hue=\"variant\", marker=\"o\")\n",
    "plt.axhline(1, ls=\"--\", c=\"gray\"); plt.yscale(\"log\"); plt.show()\n",
    "speed.to_csv(\"bf_speedup.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}